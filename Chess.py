import chess
import chess.pgn
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import numba
import os
import sys
import csv
import subprocess
import time
import math

# Import HRM model and related functions
from hrm_model import HRMChess, ValueBinDataset, train_loop

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def detect_gpu_memory_and_optimize_training():
    """
    GPU mem√≥ria detekt√°l√°s √©s automatikus batch size/learning rate optimaliz√°l√°s
    
    Returns:
        dict: Optimaliz√°lt training param√©terek
    """
    print(f"\nüîç GPU MEMORY DETECTION & TRAINING OPTIMIZATION")
    print("="*60)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available - GPU required for training!")
        print("üö® This training requires GPU acceleration.")
        print("üí° Please ensure CUDA is installed and GPU is available.")
        exit(1)
    
    try:
        # GPU inform√°ci√≥k lek√©rdez√©se
        gpu_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_device)
        
        # Mem√≥ria inform√°ci√≥k
        total_memory = torch.cuda.get_device_properties(current_device).total_memory
        reserved_memory = torch.cuda.memory_reserved(current_device)
        allocated_memory = torch.cuda.memory_allocated(current_device)
        
        # El√©rhet≈ë mem√≥ria kisz√°m√≠t√°sa (GB-ban)
        total_gb = total_memory / (1024**3)
        available_gb = (total_memory - reserved_memory) / (1024**3)
        free_gb = (total_memory - allocated_memory) / (1024**3)
        
        print(f"üñ•Ô∏è GPU Device: {gpu_name}")
        print(f"üìä Total VRAM: {total_gb:.1f} GB")
        print(f"üìä Available VRAM: {available_gb:.1f} GB")
        print(f"üìä Free VRAM: {free_gb:.1f} GB")
        print(f"üî¢ CUDA Devices: {gpu_count}")
        
        # Batch size optimaliz√°l√°s SZABAD GPU mem√≥ria alapj√°n
        if free_gb >= 20:  # B≈ëven van szabad hely high-end k√°rty√°kon
            batch_config = {
                'batch_size': 64,
                'lr_multiplier': 1.5,  # Nagyobb batch ‚Üí nagyobb LR
                'optimization_level': 'HIGH_END_FREE'
            }
            print(f"üöÄ HIGH-END FREE MEMORY ({free_gb:.1f}GB+ available)")
            
        elif free_gb >= 14:  # J√≥ mennyis√©g≈± szabad mem√≥ria
            batch_config = {
                'batch_size': 48,
                'lr_multiplier': 1.3,
                'optimization_level': 'HIGH_FREE'
            }
            print(f"üî• HIGH FREE MEMORY ({free_gb:.1f}GB available)")
            
        elif free_gb >= 10:  # K√∂zepes szabad mem√≥ria
            batch_config = {
                'batch_size': 32,
                'lr_multiplier': 1.1,
                'optimization_level': 'MID_HIGH_FREE'
            }
            print(f"‚ö° MID-HIGH FREE MEMORY ({free_gb:.1f}GB available)")
            
        elif free_gb >= 6:   # √Åtlagos szabad mem√≥ria
            batch_config = {
                'batch_size': 24,
                'lr_multiplier': 1.0,
                'optimization_level': 'MID_FREE'
            }
            print(f"üí™ MID FREE MEMORY ({free_gb:.1f}GB available)")
            
        elif free_gb >= 4:   # Kev√©s szabad mem√≥ria
            batch_config = {
                'batch_size': 16,
                'lr_multiplier': 0.9,
                'optimization_level': 'LOW_MID_FREE'
            }
            print(f"üéØ LOW-MID FREE MEMORY ({free_gb:.1f}GB available)")
            
        elif free_gb >= 2:   # Nagyon kev√©s szabad mem√≥ria
            batch_config = {
                'batch_size': 12,
                'lr_multiplier': 0.8,
                'optimization_level': 'LOW_FREE'
            }
            print(f"‚ö†Ô∏è LOW FREE MEMORY ({free_gb:.1f}GB available)")
            
        else:  # <2GB szabad VRAM
            print(f"‚ùå Insufficient free GPU memory (<2GB, available: {free_gb:.1f}GB)")
            print("üö® Training requires at least 2GB free VRAM.")
            print("üí° Please close other GPU applications or use a smaller model.")
            exit(1)
        
        # Mem√≥ria foglalts√°g alap√∫ finomhangol√°s
        memory_usage_ratio = allocated_memory / total_memory
        if memory_usage_ratio > 0.3:  # Ha m√°r 30%+ foglalt
            print(f"‚ö†Ô∏è High memory usage detected ({memory_usage_ratio*100:.1f}%)")
            print("üîß Reducing batch size for safety...")
            batch_config['batch_size'] = max(8, int(batch_config['batch_size'] * 0.7))
            batch_config['lr_multiplier'] *= 0.9
        
        # Safety check - dynamic memory test
        print(f"\nüß™ MEMORY SAFETY TEST")
        test_passed = True
        try:
            # Teszt tensor l√©trehoz√°sa a v√°lasztott batch size-hoz
            test_batch_size = batch_config['batch_size']
            test_tensor = torch.randn(test_batch_size, 72, device=device)
            test_tensor2 = torch.randn(test_batch_size, 64, 64, device=device)
            
            # Mem√≥ria felhaszn√°l√°s ellen≈ërz√©se
            test_memory = torch.cuda.memory_allocated(current_device)
            test_memory_gb = test_memory / (1024**3)
            
            print(f"   ‚úÖ Test batch ({test_batch_size}) allocated: {test_memory_gb:.2f} GB")
            
            # Cleanup
            del test_tensor, test_tensor2
            torch.cuda.empty_cache()
            
            # Ha a teszt t√∫l sok mem√≥ri√°t haszn√°l, cs√∂kkentj√ºk a batch size-t
            if test_memory_gb > free_gb * 0.6:  # Ha t√∂bb mint 60% szabad VRAM-ot haszn√°ln√°
                print(f"   ‚ö†Ô∏è Batch size too large for free memory, reducing...")
                batch_config['batch_size'] = max(8, int(batch_config['batch_size'] * 0.6))
                batch_config['lr_multiplier'] *= 0.9
                
        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                print(f"   ‚ùå Memory test failed - reducing batch size")
                batch_config['batch_size'] = max(8, int(batch_config['batch_size'] * 0.5))
                batch_config['lr_multiplier'] *= 0.8
                test_passed = False
            torch.cuda.empty_cache()
        
        # V√©gs≈ë konfigur√°ci√≥
        result = {
            'batch_size': batch_config['batch_size'],
            'lr_multiplier': batch_config['lr_multiplier'],
            'memory_gb': total_gb,
            'free_memory_gb': free_gb,  # Hozz√°adva a szabad mem√≥ria info
            'device_name': gpu_name,
            'optimization_level': batch_config['optimization_level'],
            'memory_test_passed': test_passed
        }
        
        print("\n‚úÖ OPTIMIZED TRAINING CONFIGURATION (FREE MEMORY BASED):")
        print(f"   üéØ Batch Size: {result['batch_size']}")
        print(f"   üìà LR Multiplier: {result['lr_multiplier']:.2f}x")
        print(f"   üè∑Ô∏è Level: {result['optimization_level']}")
        print(f"   üíæ Free VRAM: {free_gb:.1f}GB / {total_gb:.1f}GB total")
        print(f"   üß™ Memory Test: {'‚úÖ PASSED' if test_passed else '‚ö†Ô∏è ADJUSTED'}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå GPU detection failed: {e}")
        print(" Cannot proceed without GPU information.")
        exit(1)

def load_pgn_data(pgn_path, max_positions=None, max_moves=40, min_elo=1600):
    all_fens = []
    
    # Debug counters
    stats = {
        'total_games': 0,
        'elo_rejected': 0,
        'result_rejected': 0,
        'timecontrol_rejected': 0,
        'processed_games': 0,
        'positions_extracted': 0,
        'piece_moves': 0,
        'pawn_moves': 0,
        'captures': 0,
        'tactical_moves': 0
    }
    
    with open(pgn_path, encoding="utf-8") as pgn:
        while True:
            game = chess.pgn.read_game(pgn)
            if game is None:
                break
                
            stats['total_games'] += 1
            
            if stats['total_games'] % 1000 == 0:
                print(f"PGN: {stats['total_games']} ellen≈ërizve, {stats['processed_games']} feldolgozva, "
                      f"{stats['positions_extracted']} poz√≠ci√≥")
            
            if max_positions < stats['positions_extracted']:
                break
            
            # Sz≈±r√©s: csak megfelel≈ë j√°t√©kosok j√°tszmai
            try:
                white_elo = int(game.headers.get("WhiteElo", "0"))
                black_elo = int(game.headers.get("BlackElo", "0"))
                
                # MAGASABB ELO minimum - jobb min≈ës√©g
                if not (white_elo >= min_elo and black_elo >= min_elo and 
                       white_elo < 2800 and black_elo < 2800):
                    stats['elo_rejected'] += 1
                    continue
                    
                # Id≈ëkontroll √©s eredm√©ny sz≈±r√©s
                time_control = game.headers.get("TimeControl", "")
                result = game.headers.get("Result", "*")
                
                # Csak befejezett j√°tszm√°k
                if not (result in ["1-0", "0-1"]):  # Kiz√°rjuk a d√∂ntetleneket!
                    stats['result_rejected'] += 1
                    continue
                
                if len(time_control) <= 3:
                    stats['timecontrol_rejected'] += 1
                    continue
                        
                # Ha minden sz≈±r√©si felt√©tel teljes√ºl, feldolgozzuk a j√°tszm√°t
                board = game.board()
                node = game
                move_count = 0
                
                # K√ñZ√âPJ√ÅT√âK √©s V√âGJ√ÅT√âK hangs√∫lyoz√°sa
                opening_moves_to_skip = 8  # T√∂bb nyit√°s kihagy√°sa
                current_move = 0
                game_moves = []
                
                # El≈ëre gy≈±jtj√ºk a l√©p√©seket min≈ës√©gi sz≈±r√©shez
                temp_board = game.board()
                temp_node = game
                while temp_node.variations:
                    move = temp_node.variation(0).move
                    game_moves.append((temp_board.copy(), move))
                    temp_board.push(move)
                    temp_node = temp_node.variation(0)
                
                # INTELLIGENS L√âP√âS SZELEKT√ÅL√ÅS
                for board_state, move in game_moves:
                    current_move += 1
                    
                    # Skip opening moves
                    if current_move <= opening_moves_to_skip:
                        board.push(move)
                        node = node.variation(0)
                        continue
                    
                    # MIN≈êS√âGI SZ≈∞R√âS - csak √©rdekes l√©p√©sek
                    is_capture = board.is_capture(move)
                    is_check = board.gives_check(move)
                    is_piece_move = board.piece_at(move.from_square) and \
                                   board.piece_at(move.from_square).piece_type != chess.PAWN
                    is_tactical = is_capture or is_check or \
                                 board.is_castling(move) or \
                                 board.is_en_passant(move)
                    
                    # BALANCED SAMPLING - prefer√°ljuk a b√°bu l√©p√©seket √©s taktikai l√©p√©seket
                    include_move = False
                    
                    if is_tactical:  # Mindig befoglaljuk a taktikai l√©p√©seket
                        include_move = True
                        stats['tactical_moves'] += 1
                    elif is_piece_move:  # 80% es√©llyel befoglaljuk a b√°bu l√©p√©seket
                        if np.random.random() < 0.8:
                            include_move = True
                            stats['piece_moves'] += 1
                    else:  # Csak 30% es√©llyel befoglaljuk a gyalog l√©p√©seket
                        if np.random.random() < 0.3:
                            include_move = True
                            stats['pawn_moves'] += 1
                    
                    if include_move:
                        current_fen = board.fen()  # Store the actual FEN
                        all_fens.append(current_fen)  # Store FEN for Stockfish evaluation
                        stats['positions_extracted'] += 1
                        
                        if is_capture:
                            stats['captures'] += 1
                    
                    board.push(move)
                    node = node.variation(0)
                    move_count += 1
                    
                    if move_count >= max_moves:
                        break
                
                stats['processed_games'] += 1
                        
            except (ValueError, KeyError):
                continue  # Skip games with missing/invalid data
    
    # ENHANCED statistics
    print("\nüìä ENHANCED PGN Processing Statistics:")
    print(f"   Total games examined: {stats['total_games']:,}")
    print(f"   Successfully processed: {stats['processed_games']:,}")
    print(f"   Positions extracted: {stats['positions_extracted']:,}")
    print(f"   ‚îú‚îÄ‚îÄ Piece moves: {stats['piece_moves']:,} ({stats['piece_moves']/max(stats['positions_extracted'], 1)*100:.1f}%)")
    print(f"   ‚îú‚îÄ‚îÄ Pawn moves: {stats['pawn_moves']:,} ({stats['pawn_moves']/max(stats['positions_extracted'], 1)*100:.1f}%)")
    print(f"   ‚îú‚îÄ‚îÄ Captures: {stats['captures']:,} ({stats['captures']/max(stats['positions_extracted'], 1)*100:.1f}%)")
    print(f"   ‚îî‚îÄ‚îÄ Tactical moves: {stats['tactical_moves']:,} ({stats['tactical_moves']/max(stats['positions_extracted'], 1)*100:.1f}%)")
    
    # Duplik√°lt FEN-ek sz≈±r√©se indexekkel (mem√≥riahat√©kony)
    unique_fen_idx = {}
    for idx, fen in enumerate(all_fens):
        if fen not in unique_fen_idx:
            unique_fen_idx[fen] = idx
    num_duplicates = len(all_fens) - len(unique_fen_idx)
    if num_duplicates > 0:
        print(f"‚ö†Ô∏è Duplik√°lt poz√≠ci√≥k sz√°ma: {num_duplicates}")
    else:
        print("‚úÖ Nincsenek duplik√°lt poz√≠ci√≥k a PGN adatok k√∂z√∂tt.")
    # Csak az egyedi poz√≠ci√≥k √©s policy-k
    unique_indices = list(unique_fen_idx.values())
    all_fens = [all_fens[i] for i in unique_indices]

    print(f"‚úÖ BALANCED PGN adatok: {len(all_fens):,} poz√≠ci√≥ {stats['processed_games']} j√°tszm√°b√≥l")
    return all_fens

def get_manual_parameters():
    """Get manual hyperparameters from user"""
    print("\nüîß MANUAL PARAMETER CONFIGURATION")
    print("-" * 40)
    print("üí° Parameter Guidelines:")
    print("   ‚Ä¢ hidden_dim: 128-512 (network width)")
    print("   ‚Ä¢ N: 2-8 (high-level reasoning cycles)")
    print("   ‚Ä¢ T: 2-8 (steps per cycle)")
    print("   ‚Ä¢ Total HRM steps = N √ó T (recommended: 6-32)")
    print("   ‚Ä¢ More steps = better reasoning but slower training")
    
    # Get hidden_dim
    while True:
        try:
            hidden_dim = int(input("\nEnter hidden_dim (64-512): "))
            if 64 <= hidden_dim <= 1024:
                break
            else:
                print("‚ùå Please enter a value between 64 and 1024")
        except ValueError:
            print("‚ùå Please enter a valid integer")
    
    # Get N
    while True:
        try:
            N = int(input("Enter N - reasoning cycles (2-12): "))
            if 2 <= N <= 12:
                break
            else:
                print("‚ùå Please enter a value between 2 and 12")
        except ValueError:
            print("‚ùå Please enter a valid integer")
    
    # Get T
    while True:
        try:
            T = int(input("Enter T - steps per cycle (2-12): "))
            if 2 <= T <= 12:
                break
            else:
                print("‚ùå Please enter a value between 2 and 12")
        except ValueError:
            print("‚ùå Please enter a valid integer")
    
    total_steps = N * T
    
    # Estimate model complexity
    estimated_params = hidden_dim * (hidden_dim * 6 + 64*64) + hidden_dim * 3
    complexity_level = "Light" if total_steps <= 8 else "Medium" if total_steps <= 16 else "Heavy"
    
    print("\n‚úÖ Manual Configuration:")
    print(f"   ‚Ä¢ hidden_dim: {hidden_dim}")
    print(f"   ‚Ä¢ N: {N}, T: {T}")
    print(f"   ‚Ä¢ Total HRM steps: {total_steps}")
    print(f"   ‚Ä¢ Complexity: {complexity_level}")
    print(f"   ‚Ä¢ Estimated parameters: ~{estimated_params:,}")
    
    if total_steps > 50:
        print("‚ö†Ô∏è  Warning: Very high step count may slow training significantly")
    elif total_steps > 32:
        print("‚ö†Ô∏è  Warning: High step count may slow training")
    elif total_steps < 4:
        print("‚ö†Ô∏è  Warning: Very low step count may reduce model capacity")
    
    # Confirmation
    confirm = input("\nProceed with this configuration? (y/n): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("üîÑ Restarting parameter selection...")
        return get_manual_parameters()
    
    return hidden_dim, N, T

# Import StockfishEvaluator and ParallelStockfishEvaluator from the new module
from stockfish_eval import StockfishEvaluator, ParallelStockfishEvaluator

def create_dataset_from_games(max_positions=10000):
    """
    Dataset l√©trehoz√°sa j√°tszm√°kb√≥l - csak PGN alap√∫, puzzle n√©lk√ºl
    
    Args:
        max_positions: Maxim√°lis poz√≠ci√≥k sz√°ma a dataset-ben
    """
    import math
    import time

    print("\nüéÆ Creating dataset from games...")

    print("üì• Loading PGN games...")
    try:
        pgn_fens = load_pgn_data(
            "./lichess_db_standard_rated_2015-05.pgn",
            max_positions=max_positions,
            max_moves=30,
            min_elo=1600
        )
        print(f"‚úÖ Loaded {len(pgn_fens):,} positions from PGN")
    except:
        print("‚ö†Ô∏è PGN file not found")
        exit(0)

    all_fens = pgn_fens

    # Duplik√°lt FEN-ek sz≈±r√©se indexekkel (mem√≥riahat√©kony)
    unique_fen_idx = {}
    for idx, fen in enumerate(all_fens):
        if fen not in unique_fen_idx:
            unique_fen_idx[fen] = idx
    num_duplicates = len(all_fens) - len(unique_fen_idx)
    if num_duplicates > 0:
        print(f"‚ö†Ô∏è Duplik√°lt poz√≠ci√≥k sz√°ma: {num_duplicates}")
    else:
        print("‚úÖ Nincsenek duplik√°lt poz√≠ci√≥k a PGN adatok k√∂z√∂tt.")
    
    # Csak az egyedi poz√≠ci√≥k √©s policy-k
    unique_indices = list(unique_fen_idx.values())
    all_fens = [all_fens[i] for i in unique_indices]

    if len(all_fens) == 0:
        print("‚ùå No training data available!")
        exit(0)

    print(f"üìä Total positions loaded: {len(all_fens):,}")

    # --- Stockfish √©rt√©kel√©s minden poz√≠ci√≥ra ---
    print("\nü§ñ Evaluating all legal moves for all positions...")
    stockfish = ParallelStockfishEvaluator(stockfish_path="stockfish.exe", movetime=10, num_evaluators=int(os.cpu_count() * 0.8) or 2)
    all_move_evals = stockfish.evaluate_positions_parallel(all_fens)
    stockfish.close()

    print(f"‚úÖ Stockfish-evaluated dataset: {len(all_fens):,} positions")
    return all_fens, all_move_evals

if __name__ == "__main__":
    print("üèóÔ∏è HRM CHESS MODEL TRAINING")
    print("="*50)
    
    import os
    import sys
    print(f"Using device: {device}")
    
    # GPU MEMORY DETECTION & OPTIMIZATION
    gpu_config = detect_gpu_memory_and_optimize_training()
    
    # Load or create dataset
    dataset_path = "fen_move_score_dataset.pt"
    
    if not os.path.exists(dataset_path):
        print(f"\nüìù Dataset not found: {dataset_path}")
        print("üìä Creating new dataset...")
        
        # Ask user for dataset size
        while True:
            try:
                max_games = int(input("Enter number of games (number of games, e.g., 20000): "))
                if max_games > 0:
                    break
                else:
                    print("‚ùå Please enter a positive number")
            except ValueError:
                print("‚ùå Please enter a valid integer")
        
        print(f"üéØ Creating dataset with {max_games:,} games")
        
        # Create dataset from games and puzzles with user-specified size
        fens, moves = create_dataset_from_games(max_games)

        # Save as vector of (fen, move, score) tuples in a .pt file, with metadata
        fen_move_score_vec = []
        for fen, move_list in zip(fens, moves):
            for move_tuple in move_list:
                move, score = move_tuple
                fen_move_score_vec.append((fen, move, score))
                
        output_pt = "fen_move_score_dataset.pt"
        
        dataset_info = {
            'data': fen_move_score_vec,
            'info': {
                'created': time.time(),
                'source': 'PGN + Stockfish (all legal moves, deduped FENs)',
                'base_positions': len(fens),
                'total_positions': len(fen_move_score_vec),
                'stockfish_evaluation': 'all_legal_moves',
                'evaluation_method': 'all_moves_winpercent',
                'data_format': '(fen, move, score)',
                'number_of_games': max_games
            }
        }
        torch.save(dataset_info, output_pt)
        print(f"‚úÖ Saved {len(fen_move_score_vec):,} (fen + move, score) pairs and metadata to {output_pt}")
        
        # Use the created data
        data = dataset_info
    else:
        # Load existing dataset
        print(f"\nüì• Loading existing dataset: {dataset_path}")
        data = torch.load(dataset_path, weights_only=False)
    
    # Extract (fen + move, score) tuples from dataset_info
    dataset_info = data if 'data' in data else data.get('dataset_info', {})
    fen_move_score_vec = dataset_info['data']
    info = dataset_info['info']

    print("‚úÖ Loaded dataset:")
    print(f"   üìä Positions: {len(fen_move_score_vec):,}")
    print(f"   ü§ñ Source: {info.get('source', 'Unknown')}")
    print(f"   üéÆ Data mix: {info.get('data_mix', 'Unknown composition')}")
    print(f"   üñ•Ô∏è GPU Optimized: {info.get('gpu_optimized', False)}")

    # --- UCI move vocabulary and binning ---
    from hrm_model import generate_all_possible_uci_moves, score_to_bin
    uci_vocab = generate_all_possible_uci_moves()
    uci2idx = {uci: i for i, uci in enumerate(uci_vocab)}
    num_bins = 128  # should match model

    fen_tokens = []
    uci_tokens = []
    target_bins = []
    debug_prints = 0
    for fen, move, score in fen_move_score_vec:
        fen_ascii = [ord(c) for c in fen.ljust(77)[:77]]
        uci_idx = uci2idx.get(move)
        if uci_idx is None:
            if debug_prints < 10:
                print(f"[DEBUG] Skipped: move not in uci2idx: {move}")
                debug_prints += 1
            continue
        try:
            bin_idx = score_to_bin(float(score), num_bins=num_bins)
        except Exception as e:
            if debug_prints < 10:
                print(f"[DEBUG] Skipped: score conversion error: {score}, error: {e}")
                debug_prints += 1
            continue
        fen_tokens.append(fen_ascii)
        uci_tokens.append([uci_idx])
        target_bins.append(bin_idx)

    dataset_size = len(fen_tokens)
    print(f"\nüìä Dataset size: {dataset_size:,} positions")
    
    # MANUAL PARAMETERS
    hidden_dim, N, T = get_manual_parameters()
    
    # Apply GPU optimizations
    batch_size = gpu_config['batch_size']
    lr = 1e-4 * gpu_config['lr_multiplier']
    model_size = f"GPU_MANUAL-{N}x{T}-{gpu_config['optimization_level']}"
    
    print("\nüîß GPU OPTIMIZATIONS APPLIED:")
    print(f"   üìä Batch Size: {batch_size} (GPU-optimized)")
    print(f"   üìà Learning Rate: {lr:.6f} (base: 2e-4 √ó {gpu_config['lr_multiplier']:.2f})")
    print(f"   üñ•Ô∏è GPU Level: {gpu_config['optimization_level']}")
    
    # HRM modell l√©trehoz√°sa optimaliz√°lt param√©terekkel
    model = HRMChess(emb_dim=hidden_dim, N=N, T=T).to(device)
    
    # Model info
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    hrm_steps = N * T
    
    print("\nüèóÔ∏è MODEL ARCHITECTURE:")
    print(f"üìä Total parameters: {total_params:,}")
    print(f"üìä Trainable parameters: {trainable_params:,}")
    print(f"üîÑ HRM reasoning steps: {hrm_steps} (N={N} √ó T={T})")
    
    # GPU-optimized training configuration
    epochs = 30  # T√∂bb epoch a jobb konvergenci√°√©rt
    
    print("\n‚öôÔ∏è GPU-OPTIMIZED TRAINING CONFIGURATION:")
    print(f"   ‚Ä¢ Model: {model_size}")
    print(f"   ‚Ä¢ Batch size: {batch_size} (GPU-optimized)")
    print(f"   ‚Ä¢ Learning rate: {lr:.6f} (GPU-scaled)")
    print("   ‚Ä¢ Warmup epochs: 3 (linear warmup + cosine annealing)")
    print(f"   ‚Ä¢ Total epochs: {epochs}")
    print(f"   ‚Ä¢ HRM steps: {N}√ó{T}={N*T}")
    print(f"   ‚Ä¢ Parameters: {total_params:,}")
    print(f"   ‚Ä¢ Dataset: {dataset_size:,} positions")
    print(f"   üñ•Ô∏è GPU: {gpu_config['device_name']} ({gpu_config['memory_gb']:.1f} GB)")
    print(f"   üè∑Ô∏è Optimization Level: {gpu_config['optimization_level']}")
    
    # Create value bin dataset
    dataset = ValueBinDataset(fen_tokens, uci_tokens, target_bins)
    print(f"\nüìä Dataset: {len(dataset):,} positions")
    print("üöÄ Starting GPU-optimized HRM training with warmup...")
    
    # Train with GPU-optimized parameters and warmup
    train_loop(model, dataset, epochs=epochs, batch_size=batch_size, lr=lr, warmup_epochs=3, device=device)
    
    # Save final model with hyperparameters and GPU info
    final_checkpoint = {
        'model_state_dict': model.state_dict(),
        'hyperparams': {
            'hidden_dim': hidden_dim,
            'N': N,
            'T': T,
            'input_dim': 20
        },
        'training_info': {
            'epochs': epochs,
            'batch_size': batch_size,
            'lr': lr,
            'warmup_epochs': 3,
            'dataset_size': len(dataset),
            'total_params': total_params,
            'training_mode': 'policy_value_warmup',
            'gpu_optimized': True,
            'gpu_config': gpu_config
        }
    }
    model_path = "hrm_chess_model.pt"
    torch.save(final_checkpoint, model_path)
    print("\n‚úÖ Training completed!")
    print("üíæ Model saved to: {model_path}")
    print("üèÜ HRM (N={N}, T={T}, hidden_dim={hidden_dim}) with {total_params:,} parameters")
    print("üìä Trained on {len(dataset):,} positions with Warmup mode")
    print("üéÆ Dataset: Balanced PGN games + tactical puzzles for enhanced gameplay")
    print("üî• Warmup: 3 epochs with linear warmup + cosine annealing")
